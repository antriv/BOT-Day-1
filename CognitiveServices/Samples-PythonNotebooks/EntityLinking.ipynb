{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Linking with Microsoft Cognitive Services Entity Linking Intelligence Service API\n",
    "\n",
    "Entity Linking is a natural language processing tool to help analyzing text for your application. Entity Linking recognize a named-entity from given text and aligning a textual mention of the entity to an appropriate entry in a knowledge base. -*from ELIS API Reference*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### For python 2 and 3 compatibility we have a few imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Import compatibility libraries (python 2/3 support)\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "# Python 3\n",
    "try:\n",
    "    import json\n",
    "    from urllib.request import urlopen, Request\n",
    "    from urllib.parse import urlparse, urlencode\n",
    "    from http.client import HTTPSConnection\n",
    "# Python 2.7\n",
    "except ImportError:\n",
    "    import json\n",
    "    from urlparse import urlparse\n",
    "    from urllib import urlencode\n",
    "    from urllib2 import Request, urlopen\n",
    "    from httplib import HTTPSConnection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load our configuration file (just has subscription key as of now)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response = urlopen('https://gist.githubusercontent.com/antriv/a6962d2c7580a0f7db4b7aabd6d768c5/raw/66d2f4219a566e2af995f6ce160e48851bf7811e/config.json')\n",
    "data = response.read().decode(\"utf-8\")\n",
    "CONFIG = json.loads(data)\n",
    "subscription_key = CONFIG['subscription_key_ELIS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load our text data from a file**\n",
    "\n",
    "ELIS expects it in UTF-8 encoded plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = urlopen('https://raw.githubusercontent.com/michhar/bot-education/master/CognitiveServices/Samples/KNOWLEDGE_API/python/sample_text.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in a process to decode the strange quotes\n",
    "text = f.read().decode('utf-8')\n",
    "\n",
    "# Substitute decoded quotes with regular single quotes\n",
    "import re\n",
    "text = re.sub('\\u2019|\\u201c|\\u201d', \"'\", text).replace('\\n', ' ')\n",
    "text = text.encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try some of your own text either in a file or a string literal in a code cell here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up the header and parameter part of request**\n",
    "\n",
    "Our content type is `'text/plain'` this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http headers needed for POST request\n",
    "# we keep these as dict\n",
    "headers = {\n",
    "    # Request headers - note content type is text/plain!\n",
    "    'Content-Type': 'text/plain',\n",
    "    'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "}\n",
    "\n",
    "# params will be added to POST in url request\n",
    "# right now it's empty because for this request we don't need any params\n",
    "# although we could have included 'selection' and 'offset' - see docs\n",
    "params = urlencode({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make the API request call**\n",
    "\n",
    "Given a specific paragraph of text within a document, the Entity Linking Intelligence Service will recognize and identify each separate entity based on the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"entities\": [\n",
      "        {\n",
      "            \"matches\": [\n",
      "                {\n",
      "                    \"entries\": [\n",
      "                        {\n",
      "                            \"offset\": 545\n",
      "                        }\n",
      "                    ],\n",
      "                    \"text\": \"Department of Computer Science\"\n",
      "                }\n",
      "            ],\n",
      "            \"name\": \"Computer Science\",\n",
      "            \"score\": 1.0,\n",
      "            \"wikipediaId\": \"Computer science\"\n",
      "        },\n",
      "        {\n",
      "            \"matches\": [\n",
      "                {\n",
      "                    \"entries\": [\n",
      "                        {\n",
      "                            \"offset\": 632\n",
      "                        }\n",
      "                    ],\n",
      "                    \"text\": \"IBM's\"\n",
      "                }\n",
      "            ],\n",
      "            \"name\": \"IBM\",\n",
      "            \"score\": 0.999,\n",
      "            \"wikipediaId\": \"IBM\"\n",
      "        },\n",
      "        {\n",
      "            \"matches\": [\n",
      "                {\n",
      "                    \"entries\": [\n",
      "                        {\n",
      "                            \"offset\": 638\n",
      "                        }\n",
      "                    ],\n",
      "                    \"text\": \"Watson\"\n",
      "                }\n",
      "            ],\n",
      "            \"name\": \"Watson\",\n",
      "            \"score\": 1.0,\n",
      "            \"wikipediaId\": \"Watson (computer)\"\n",
      "        },\n",
      "        {\n",
      "            \"matches\": [\n",
      "                {\n",
      "                    \"entries\": [\n",
      "                        {\n",
      "                            \"offset\": 648\n",
      "                        }\n",
      "                    ],\n",
      "                    \"text\": \"Jeopardy\"\n",
      "                }\n",
      "            ],\n",
      "            \"name\": \"Jeopardy!\",\n",
      "            \"score\": 0.908,\n",
      "            \"wikipediaId\": \"Jeopardy!\"\n",
      "        },\n",
      "        {\n",
      "            \"matches\": [\n",
      "                {\n",
      "                    \"entries\": [\n",
      "                        {\n",
      "                            \"offset\": 896\n",
      "                        }\n",
      "                    ],\n",
      "                    \"text\": \"Intelligence\"\n",
      "                }\n",
      "            ],\n",
      "            \"name\": \"Artificial intelligence\",\n",
      "            \"score\": 0.376,\n",
      "            \"wikipediaId\": \"Artificial intelligence\"\n",
      "        },\n",
      "        {\n",
      "            \"matches\": [\n",
      "                {\n",
      "                    \"entries\": [\n",
      "                        {\n",
      "                            \"offset\": 1238\n",
      "                        }\n",
      "                    ],\n",
      "                    \"text\": \"Computer Vision\"\n",
      "                }\n",
      "            ],\n",
      "            \"name\": \"Computer vision\",\n",
      "            \"score\": 0.867,\n",
      "            \"wikipediaId\": \"Computer vision\"\n",
      "        },\n",
      "        {\n",
      "            \"matches\": [\n",
      "                {\n",
      "                    \"entries\": [\n",
      "                        {\n",
      "                            \"offset\": 1263\n",
      "                        }\n",
      "                    ],\n",
      "                    \"text\": \"UT Austin\"\n",
      "                }\n",
      "            ],\n",
      "            \"name\": \"University of Texas at Austin College of Fine Arts\",\n",
      "            \"score\": 0.714,\n",
      "            \"wikipediaId\": \"University of Texas at Austin\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn = HTTPSConnection('api.projectoxford.ai')\n",
    "    \n",
    "    # Post method request - note:  body of request is converted from json to string\n",
    "    conn.request(\"POST\", \"/entitylinking/v1.0/link?%s\" % params, body = text, headers = headers)\n",
    "    response = conn.getresponse()\n",
    "    data = response.read()\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(\"[Error: {0}] \".format(e))\n",
    "    \n",
    "# Print the results - json response format\n",
    "print(json.dumps(json.loads(data), \n",
    "           sort_keys=True,\n",
    "           indent=4, \n",
    "           separators=(',', ': ')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
